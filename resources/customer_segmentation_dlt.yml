# The main pipeline for customer segmentation
resources:
  pipelines:
    customer_segmentation_pipeline:
      name: customer_segmentation_pipeline  # Name of the pipeline
      target: customer_segmentation_${bundle.environment}  # Output target with environment variable
      clusters:
        - label: default
          num_workers: 1
          node_type_id: Standard_DS3_v2
          driver_node_type_id: Standard_DS3_v2
          init_scripts:
          - workspace : 
              destination : "${workspace.file_path}/src/init_scripts/dlt_init_script.sh"
      libraries:
        - notebook:
            path: ../src/01_bronze_table.py
        - notebook:
            path: ../src/02_silver_table.py
        - notebook:
            path: ../src/03_gold_table.py
      
      development: true
      configuration:
        bundle.sourcePath: /Workspace/${workspace.file_path}/src
        cloudFiles.inputPath: "/FileStore/customer_segmentation/train/"  # Path to the raw CSVs in DBFS (Auto Loader watches this directory)
        cloudFiles.format: "csv"  # Input data format
        cloudFiles.maxFilesPerTrigger: "1"  # Control the number of files processed per trigger
        cloudFiles.header: "true"  # Ensure that Auto Loader recognizes the header in CSV
        bronze_schema_path: /Workspace/${workspace.file_path}/resources/dlt_schemas.yml
        bronze_schema_name: "bronze_schema"
        gold_table_config_path: /Workspace/${workspace.file_path}/resources/gold_table_config.yml
        pipeline_path: "dbfs:/FileStore/customer_segmentation/pipelines/preprocessing"