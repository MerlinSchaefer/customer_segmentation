{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee353e42-ff58-4955-9608-12865bd0950e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# EDA notebook\n",
    "\n",
    "This  notebook is used to explore the data iteratively. The actual transformations used in the production workflow is found in the dlt pipeline and ML training workflow. These are also more optimized using Spark etc. whereas here other tools are used as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0af3d04-b7e4-4f04-8860-844e268a7b7b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bca260b-13d1-448f-8082-30b60a85c9ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_data = spark.read.table(\"customer_segmentation.train_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f77a2340-f294-40cc-8356-3a0a1b5c8865",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e1f7e7f-d45b-4f86-9725-8364fc97f9a0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(train_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc574fc6-efe7-48d1-9b92-d9a17d412cef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(train_data.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73f6dbf9-5ce5-48d6-93a4-b68d1e3d30cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dbutils.data.summarize(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b03be7b1-4708-4ee5-ad75-45178b3db297",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Proposed Bronze to Silver Cleaning Steps for training data\n",
    "\n",
    "- Schema changes:\n",
    "  - standardize column names (no whitespace, no caps, underscores for spaces)\n",
    "  - convert Yes/No cols to binary 0/1 (Ever_Married,Graduated)\n",
    "  - Age, Family Size should be Int not Str\n",
    "  - Work Experience should be Int/Flouat not Str\n",
    "\n",
    "- Quality Checks\n",
    " - report any missings\n",
    " - remove missings in ID (we don't know who this is, so we don't segment them) or segment (target variable, data without should not be in train batch)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87c3c961-e34f-4cea-af11-63b8e3f4df24",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(train_data.toPandas(), hue=\"Segmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a48e51d-d327-410d-9904-55b0248fce5c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_pd = train_data.toPandas()\n",
    "df_pd.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4fc38f9-b29c-4ff4-b340-1a814dd964f7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "transform categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ec00d75-cf11-4d3f-940d-daf8bc5994b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5450fc1a-9169-4ffc-8df3-bc0e4cb14f53",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# look into cols: cardinality, outliers, NAs\n",
    "cat_cols = [\"Gender\", \"Ever_Married\", \"Graduated\", \"Profession\", \"Spending_Score\", \"Var_1\"]\n",
    "\n",
    "for col in cat_cols:\n",
    "    print(f\"col: {col}, unique values: {df_pd[col].nunique()}\")\n",
    "    print(df_pd[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c161f378-5452-4d35-908e-3c428205a944",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "no high cardinality, let's look at NAs\n",
    "- Ever_Married and Graduated should be a clear yes or no: either impute, drop or default to No\n",
    "- None in Profession and Var_1 could be converted to \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0e49ca1-d1a1-4787-be2c-2c31d7a1fb02",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "na_percentage = df_pd[cat_cols].isnull().mean() * 100\n",
    "print(\"Percentage of NAs in categorical columns:\")\n",
    "print(na_percentage)\n",
    "\n",
    "# Display rows from the dataframe where any of the categorical columns have NAs\n",
    "sample_nas = df_pd[df_pd[cat_cols].isnull().any(axis=1)]\n",
    "display(sample_nas.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1886f0b-89ef-4dad-a828-2e0099926e9a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "there seem to be some odd values such  a lawyer, who has not graduated and has no work experience, these could be students, but some are to old to be students. -> make Student col? CHECK AGAIN WHAT DEFINES GRADUATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ed1d6ca-7949-4021-816c-96b7fbf70b5a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataframe that contains rows with None values in more than one column\n",
    "df_with_multiple_nones = df_pd[df_pd[cat_cols].isnull().sum(axis=1) > 1]\n",
    "display(df_with_multiple_nones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e6ed8a5-568b-4d01-a139-9655b091ebb2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "there aren't too many here, either drop or impute, rest of the data seems to be there, could impute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d193435b-1c8d-4c1e-9431-ae8d5c060ee7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# check overall missings\n",
    "na_percentage = df_pd.isnull().mean() * 100\n",
    "print(\"Percentage of NAs in categorical columns:\")\n",
    "print(na_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d121e849-4e27-4a07-82a7-1dfb81683998",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataframe that contains rows with None values in more than one column\n",
    "df_with_multiple_nones = df_pd[df_pd.isnull().sum(axis=1) > 1]\n",
    "display(df_with_multiple_nones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51feb354-b3c9-429d-81db-b801a273dc29",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# handle missings\n",
    "# Other category for Profession NAs\n",
    "df_pd['Profession'].fillna('Other', inplace=True)\n",
    "# Assume \"No\" for Ever_Married NAs\n",
    "df_pd['Ever_Married'].fillna('No', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbf2f866-337b-48f6-9d0c-19a0fcf3c283",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c120dde-2ecd-44a5-bd8c-a7dbe0c3e5d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "target = df_pd[\"Segmentation\"]\n",
    "df_pd.drop([\"ID\",\"inserted_at\",\"Segmentation\"],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ca3fdf4-e22d-4349-adf4-fac862291f8b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Enconde to look for correlation etc.\n",
    "\n",
    "- Label encode binary cols: Gender, Married, Graduated\n",
    "- onehot encode: profession, var_1\n",
    "- ordinal_encode: Spendingscore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31207405-1ba6-46b9-b7d3-8e98cf0c9647",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define categorical columns to be encoded differently\n",
    "categorical_columns_onehot = ['Profession', 'Var_1']  # For OneHotEncoder\n",
    "categorical_columns_ordinal = ['Spending_Score']\n",
    "categorical_columns_custom = [\"Ever_Married\", \"Graduated\", \"Gender\"]  # For custom encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3970b911-c5c1-4db2-9956-a2bc4c5289bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for col in categorical_columns_custom:\n",
    "    print(df_pd[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d607ab0-9403-4bef-a377-2ff8b96cc451",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Custom mapping for categorical columns\n",
    "custom_mapping = [\n",
    "    ({'Yes': 1, 'No': 0}, [\"Ever_Married\", \"Graduated\"]),  # Mapping for Ever_Married and Graduated\n",
    "    ({'Male': 1, 'Female': 0}, [\"Gender\"])  # Mapping for Gender\n",
    "]\n",
    "\n",
    "# Custom encoding for Ever_Married, Graduated, and Gender\n",
    "for mapping, columns in custom_mapping:\n",
    "    for column in columns:\n",
    "        df_pd[column] = df_pd[column].map(mapping)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9932eb9d-27a2-4ab9-aec8-2948b27429d7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "\n",
    "# Define transformers for the column transformer excluding 'custom' as it's already handled\n",
    "transformers = [\n",
    "    ('onehot', OneHotEncoder(), categorical_columns_onehot),\n",
    "    ('ordinal', OrdinalEncoder(categories=[['Low', 'Average', 'High']]), categorical_columns_ordinal)\n",
    "]\n",
    "\n",
    "# Initialize ColumnTransformer with remainder columns passed through\n",
    "column_transformer = ColumnTransformer(transformers, remainder='passthrough')\n",
    "\n",
    "# Apply ColumnTransformer\n",
    "df_encoded_array = column_transformer.fit_transform(df_pd)\n",
    "\n",
    "# Extract the feature names for onehot encoded columns\n",
    "onehot_columns = column_transformer.named_transformers_['onehot'].get_feature_names_out(categorical_columns_onehot)\n",
    "\n",
    "# Combine all column names, ensuring the order matches the original DataFrame as closely as possible\n",
    "# Start with onehot encoded columns, then ordinal, and finally the remainder\n",
    "new_columns = list(onehot_columns) + categorical_columns_ordinal + [col for col in df_pd.columns if col not in categorical_columns_onehot and col not in categorical_columns_ordinal]\n",
    "\n",
    "# Convert the array back to a DataFrame with the correct column names\n",
    "df_encoded = pd.DataFrame(df_encoded_array, columns=new_columns)\n",
    "\n",
    "display(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13378452-55dc-4f25-90d2-6e7dd6b6b45a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Impute rest of cols with KNN for now\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Impute missing values in the DataFrame\n",
    "df_pd_imputed = pd.DataFrame(imputer.fit_transform(df_encoded), columns=df_encoded.columns)\n",
    "\n",
    "display(df_pd_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee567693-eaf8-43b1-b9ef-b5854255b1c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "features = df_pd_imputed.copy()\n",
    "\n",
    "complete = features.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aad4f48a-60c8-4e1c-875b-9a76e08390d6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# # add target col for rest of eda with encoding of Segmentation column in a simple numerical manner\n",
    "segmentation_mapping = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
    "complete['Segmentation'] = target.map(segmentation_mapping)\n",
    "\n",
    "complete_no_ohe = complete.drop(columns=onehot_columns)\n",
    "# Recalculating correlation\n",
    "corr_matrix = complete_no_ohe.corr()\n",
    "display(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dae1b31e-9515-4356-b777-60a707219e2c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(corr_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ff02cc4-4d26-4f22-aec0-aba192ab52f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(complete_no_ohe, diag_kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "986a91e2-6e90-4fe3-9f97-50b1295ee8de",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Correlations make sense, no very large ones -> colinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3265d8a4-49ba-4531-a821-c434e6ad67c0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Figure out for ML\n",
    "\n",
    "- how to deal with NA in Work Experience and Family Size (this seems different then \"zero\")\n",
    "- remove ID?\n",
    "- how many unique professions are there? do we need to group, same with \"Var_1\"\n",
    "- what are the relationships between the categorical columns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "825162e6-0c29-47ba-9b88-35877fb09407",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "steps for silver to gold(ml-features)\n",
    "- remove ID, remove target col (Segmentation)\n",
    "- encode and impute using spark\n",
    "\n",
    "steps for silver to gold(target)\n",
    "- take target \n",
    "\n",
    "steps for silver to gold(analytics)\n",
    "- impute NAs (look for other methods than KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3b2b30f-4a81-4044-a592-3b360aa9c6ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "EDA",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
